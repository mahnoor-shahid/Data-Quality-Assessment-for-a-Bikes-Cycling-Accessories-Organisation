{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Assessment for a Medium Size Bikes & Cycling Accessories Organization\n",
    "\n",
    "> This project was done under the umbrella of KPMG internship experience. I was provided data sets of an organization targeting a client who wants a feedback from us on their dataset quality and how this can be improved.\n",
    "\n",
    "### Purpose \n",
    "Primarily, Sprocket Central Pty Ltd needs help with its customer and transactions data. The organisation has a large dataset relating to its customers, but their team is unsure how to effectively analyse it to help optimise its marketing strategy. \n",
    "\n",
    "“the importance of optimising the quality of customer datasets cannot be underestimated. The better the quality of the dataset, the better chance you will be able to use it drive company growth.” \n",
    "\n",
    "Perform the preliminary data exploration and identify ways to improve the quality of Sprocket Central Pty Ltd’s data.\n",
    "\n",
    "### Datasets\n",
    "The client provided KPMG with 3 datasets:\n",
    "- Customer Demographic \n",
    "- Customer Addresses\n",
    "- Transactions data in the past 3 months\n",
    "\n",
    "### Data Quality Framework Table\n",
    "Using the dimensions included in the Data Quality Framework, I will assess the quality of these datasets. Followings are the dimesnions provided by the Data Quality Framework: \n",
    "- Completeness : How much information all entities have. Number of missing values.\n",
    "- Consistency : How conistent is your Data. Number of inconsistencies in your data.\n",
    "- Accuarcy : How accurate is your Data. Number of errors in you data.\n",
    "- Relevancy/Auditability : Relevanct data in your entities. Number of irrelavant values.\n",
    "- Validity : Validated data with allowable values.\n",
    "- Uniqueness: How much uniques is your data. Number of duplicated values.\n",
    "- Timeliness: Updated data. Current data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas library for i/o and dataframes \n",
    "import pandas as pd\n",
    "\n",
    "# loading dataset and extracting sheets\n",
    "dataset = pd.ExcelFile('Raw_Data_provided_by_Organisation.xlsx')\n",
    "\n",
    "# parsing sheets\n",
    "Transactions = dataset.parse('Transactions', header=0)\n",
    "NewCustomerList = dataset.parse('NewCustomerList')\n",
    "CustomerDemographic = dataset.parse('CustomerDemographic')\n",
    "CustomerAddress = dataset.parse('CustomerAddress')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring and Analyzing Data Quality of Sheet: Transactions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   transaction_id  product_id  customer_id transaction_date  online_order  \\\n",
      "0               1           2         2950       2017-02-25           0.0   \n",
      "1               2           3         3120       2017-05-21           1.0   \n",
      "2               3          37          402       2017-10-16           0.0   \n",
      "3               4          88         3135       2017-08-31           0.0   \n",
      "4               5          78          787       2017-10-01           1.0   \n",
      "\n",
      "  order_status           brand product_line product_class product_size  \\\n",
      "0     Approved           Solex     Standard        medium       medium   \n",
      "1     Approved   Trek Bicycles     Standard        medium        large   \n",
      "2     Approved      OHM Cycles     Standard           low       medium   \n",
      "3     Approved  Norco Bicycles     Standard        medium       medium   \n",
      "4     Approved  Giant Bicycles     Standard        medium        large   \n",
      "\n",
      "   list_price  standard_cost  product_first_sold_date  \n",
      "0       71.49          53.62                  41245.0  \n",
      "1     2091.47         388.92                  41701.0  \n",
      "2     1793.43         248.82                  36361.0  \n",
      "3     1198.46         381.10                  36145.0  \n",
      "4     1765.30         709.48                  42226.0  \n"
     ]
    }
   ],
   "source": [
    "# display data inside sheet\n",
    "print(Transactions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Consistency and Validity of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   transaction_id           20000 non-null  int64         \n",
      " 1   product_id               20000 non-null  int64         \n",
      " 2   customer_id              20000 non-null  int64         \n",
      " 3   transaction_date         20000 non-null  datetime64[ns]\n",
      " 4   online_order             19640 non-null  float64       \n",
      " 5   order_status             20000 non-null  object        \n",
      " 6   brand                    19803 non-null  object        \n",
      " 7   product_line             19803 non-null  object        \n",
      " 8   product_class            19803 non-null  object        \n",
      " 9   product_size             19803 non-null  object        \n",
      " 10  list_price               20000 non-null  float64       \n",
      " 11  standard_cost            19803 non-null  float64       \n",
      " 12  product_first_sold_date  19803 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(3), object(5)\n",
      "memory usage: 2.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display columns of dataset Transactions\n",
    "print(Transactions.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 13)\n"
     ]
    }
   ],
   "source": [
    "# checking the shape of your data\n",
    "print(Transactions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlights of Consistency and Validity in Transactions\n",
    "Transactions dataset has 20000 records with 13 columns. \n",
    "- Out of which, 3 are of datatype **int64** which are keys. \n",
    "- One is the date **datetime64** in format **MM/DD/YYYY**. The date format used to capture DOB of customers is **YYYY-MM-DD**. It would be better if it is kept consistent.\n",
    "- Another one is Online Order which is captured in a column of **float64** datatype, however the values are **boolean**, that is true and false. \n",
    "- 5 columns are of datatype **object** which are order_status, brand, product_line, product_class, product_size. \n",
    "- Last 3 columns are of datatype **float64** again from which one of them is a date and should be **datetime64** and must be in the standard format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Completeness of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Total Values  Null_values  \\\n",
      "online_order                    19640          360   \n",
      "brand                           19803          197   \n",
      "product_line                    19803          197   \n",
      "product_class                   19803          197   \n",
      "product_size                    19803          197   \n",
      "standard_cost                   19803          197   \n",
      "product_first_sold_date         19803          197   \n",
      "transaction_id                  20000            0   \n",
      "product_id                      20000            0   \n",
      "customer_id                     20000            0   \n",
      "transaction_date                20000            0   \n",
      "order_status                    20000            0   \n",
      "list_price                      20000            0   \n",
      "\n",
      "                         Percentage of Missing Values  \n",
      "online_order                                 1.832994  \n",
      "brand                                        0.994799  \n",
      "product_line                                 0.994799  \n",
      "product_class                                0.994799  \n",
      "product_size                                 0.994799  \n",
      "standard_cost                                0.994799  \n",
      "product_first_sold_date                      0.994799  \n",
      "transaction_id                               0.000000  \n",
      "product_id                                   0.000000  \n",
      "customer_id                                  0.000000  \n",
      "transaction_date                             0.000000  \n",
      "order_status                                 0.000000  \n",
      "list_price                                   0.000000  \n"
     ]
    }
   ],
   "source": [
    "# looking for the null values\n",
    "total_null_values = Transactions.isnull().sum()\n",
    "\n",
    "# calculating total values\n",
    "total_values = Transactions.count().sort_values(ascending=True) \n",
    "\n",
    "# calculating the percentage of null values\n",
    "null_values_percentage = total_null_values/total_values *100\n",
    "\n",
    "# converting to dataframe of missing values\n",
    "missing_values = pd.concat({'Total Values' : total_values, 'Null_values': total_null_values, 'Percentage of Missing Values': null_values_percentage}, axis=1)\n",
    "\n",
    "# display missing values\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlights of Completeness in Transactions\n",
    "- Order Online columns has about 1.83% of null values. There are 360 records in which order_online was not captured.\n",
    "- Columns brand, product_line, product_class, product_size, standard_cost, product_first_sold_date also has a percentage of 0.995% missing values that is 197 null values, which should not be missing if product_id is inherited and the details of the product cannot be missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Accuracy of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                brand product_line product_class\n",
      "34     Norco Bicycles         Road        medium\n",
      "39     Norco Bicycles         Road        medium\n",
      "54     Norco Bicycles     Standard           low\n",
      "60         OHM Cycles         Road          high\n",
      "63      Trek Bicycles     Standard        medium\n",
      "...               ...          ...           ...\n",
      "19921  Norco Bicycles         Road        medium\n",
      "19941      OHM Cycles     Standard           low\n",
      "19967        WeareA2B     Standard        medium\n",
      "19987  Norco Bicycles         Road        medium\n",
      "19988  Norco Bicycles     Standard           low\n",
      "\n",
      "[1378 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# checking a single product id and its details\n",
    "bool_series = Transactions['product_id'] == 0\n",
    "\n",
    "product_id_0 = Transactions[bool_series]\n",
    "\n",
    "#view the product details\n",
    "print(product_id_0[['brand', 'product_line','product_class']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlights of Accuracy in Transactions\n",
    "A single product ID should be referencing a single product with unique values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Uniqueness of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of duplicated records in Transactions dataset is 0\n"
     ]
    }
   ],
   "source": [
    "# looking for duplicated values\n",
    "duplicated_values = Transactions.duplicated()\n",
    "\n",
    "# number of duplicated values in dataset\n",
    "print(\"The number of duplicated records in Transactions dataset is {}\".format(duplicated_values.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlights of Uniqueness in Transactions\n",
    "Transaction records are unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring and Analyzing Data Quality of Sheet: NewCustomerList, Customer Demographic and Customer Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  first_name  last_name  gender  past_3_years_bike_related_purchases  \\\n",
      "0    Chickie    Brister    Male                                   86   \n",
      "1      Morly     Genery    Male                                   69   \n",
      "2    Ardelis  Forrester  Female                                   10   \n",
      "3     Lucine      Stutt  Female                                   64   \n",
      "4    Melinda     Hadlee  Female                                   34   \n",
      "\n",
      "         DOB                   job_title job_industry_category  \\\n",
      "0 1957-07-12             General Manager         Manufacturing   \n",
      "1 1970-03-22         Structural Engineer              Property   \n",
      "2 1974-08-28      Senior Cost Accountant    Financial Services   \n",
      "3 1979-01-28  Account Representative III         Manufacturing   \n",
      "4 1965-09-21           Financial Analyst    Financial Services   \n",
      "\n",
      "      wealth_segment deceased_indicator owns_car  ...  state    country  \\\n",
      "0      Mass Customer                  N      Yes  ...    QLD  Australia   \n",
      "1      Mass Customer                  N       No  ...    NSW  Australia   \n",
      "2  Affluent Customer                  N       No  ...    VIC  Australia   \n",
      "3  Affluent Customer                  N      Yes  ...    QLD  Australia   \n",
      "4  Affluent Customer                  N       No  ...    NSW  Australia   \n",
      "\n",
      "   property_valuation Unnamed: 16 Unnamed: 17  Unnamed: 18  Unnamed: 19  \\\n",
      "0                   6        0.91      1.1375     1.421875     1.208594   \n",
      "1                  11        0.59      0.5900     0.737500     0.626875   \n",
      "2                   5        0.49      0.4900     0.490000     0.490000   \n",
      "3                   1        1.01      1.2625     1.262500     1.262500   \n",
      "4                   9        0.73      0.7300     0.912500     0.912500   \n",
      "\n",
      "   Unnamed: 20  Rank     Value  \n",
      "0            1     1  1.718750  \n",
      "1            1     1  1.718750  \n",
      "2            1     1  1.718750  \n",
      "3            4     4  1.703125  \n",
      "4            4     4  1.703125  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# display data of sheet NewCustomerList\n",
    "print(NewCustomerList.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id      first_name  last_name  gender  \\\n",
      "0            1         Laraine  Medendorp       F   \n",
      "1            2             Eli    Bockman    Male   \n",
      "2            3           Arlin     Dearle    Male   \n",
      "3            4          Talbot        NaN    Male   \n",
      "4            5  Sheila-kathryn     Calton  Female   \n",
      "\n",
      "   past_3_years_bike_related_purchases        DOB               job_title  \\\n",
      "0                                   93 1953-10-12     Executive Secretary   \n",
      "1                                   81 1980-12-16  Administrative Officer   \n",
      "2                                   61 1954-01-20      Recruiting Manager   \n",
      "3                                   33 1961-10-03                     NaN   \n",
      "4                                   56 1977-05-13           Senior Editor   \n",
      "\n",
      "  job_industry_category     wealth_segment deceased_indicator  \\\n",
      "0                Health      Mass Customer                  N   \n",
      "1    Financial Services      Mass Customer                  N   \n",
      "2              Property      Mass Customer                  N   \n",
      "3                    IT      Mass Customer                  N   \n",
      "4                   NaN  Affluent Customer                  N   \n",
      "\n",
      "                                             default owns_car  tenure  \n",
      "0                                                 \"'      Yes    11.0  \n",
      "1                       <script>alert('hi')</script>      Yes    16.0  \n",
      "2                                2018-02-01 00:00:00      Yes    15.0  \n",
      "3  () { _; } >_[$($())] { touch /tmp/blns.shellsh...       No     7.0  \n",
      "4                                                NIL      Yes     8.0  \n"
     ]
    }
   ],
   "source": [
    "# display data of sheet Customer Demographic\n",
    "print(CustomerDemographic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id              address  postcode            state    country  \\\n",
      "0            1   060 Morning Avenue      2016  New South Wales  Australia   \n",
      "1            2  6 Meadow Vale Court      2153  New South Wales  Australia   \n",
      "2            4   0 Holy Cross Court      4211              QLD  Australia   \n",
      "3            5  17979 Del Mar Point      2448  New South Wales  Australia   \n",
      "4            6     9 Oakridge Court      3216              VIC  Australia   \n",
      "\n",
      "   property_valuation  \n",
      "0                  10  \n",
      "1                  10  \n",
      "2                   9  \n",
      "3                   4  \n",
      "4                   9  \n"
     ]
    }
   ],
   "source": [
    "# display data of sheet Customer Address\n",
    "print(CustomerAddress.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Consistency and Validity of Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 23 columns):\n",
      " #   Column                               Non-Null Count  Dtype         \n",
      "---  ------                               --------------  -----         \n",
      " 0   first_name                           1000 non-null   object        \n",
      " 1   last_name                            971 non-null    object        \n",
      " 2   gender                               1000 non-null   object        \n",
      " 3   past_3_years_bike_related_purchases  1000 non-null   int64         \n",
      " 4   DOB                                  983 non-null    datetime64[ns]\n",
      " 5   job_title                            894 non-null    object        \n",
      " 6   job_industry_category                835 non-null    object        \n",
      " 7   wealth_segment                       1000 non-null   object        \n",
      " 8   deceased_indicator                   1000 non-null   object        \n",
      " 9   owns_car                             1000 non-null   object        \n",
      " 10  tenure                               1000 non-null   int64         \n",
      " 11  address                              1000 non-null   object        \n",
      " 12  postcode                             1000 non-null   int64         \n",
      " 13  state                                1000 non-null   object        \n",
      " 14  country                              1000 non-null   object        \n",
      " 15  property_valuation                   1000 non-null   int64         \n",
      " 16  Unnamed: 16                          1000 non-null   float64       \n",
      " 17  Unnamed: 17                          1000 non-null   float64       \n",
      " 18  Unnamed: 18                          1000 non-null   float64       \n",
      " 19  Unnamed: 19                          1000 non-null   float64       \n",
      " 20  Unnamed: 20                          1000 non-null   int64         \n",
      " 21  Rank                                 1000 non-null   int64         \n",
      " 22  Value                                1000 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(5), int64(6), object(11)\n",
      "memory usage: 179.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display columns of dataset NewCustomerList\n",
    "print(NewCustomerList.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 23)\n"
     ]
    }
   ],
   "source": [
    "# checking the shape of your data\n",
    "print(NewCustomerList.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                               Non-Null Count  Dtype         \n",
      "---  ------                               --------------  -----         \n",
      " 0   customer_id                          4000 non-null   int64         \n",
      " 1   first_name                           4000 non-null   object        \n",
      " 2   last_name                            3875 non-null   object        \n",
      " 3   gender                               4000 non-null   object        \n",
      " 4   past_3_years_bike_related_purchases  4000 non-null   int64         \n",
      " 5   DOB                                  3913 non-null   datetime64[ns]\n",
      " 6   job_title                            3494 non-null   object        \n",
      " 7   job_industry_category                3344 non-null   object        \n",
      " 8   wealth_segment                       4000 non-null   object        \n",
      " 9   deceased_indicator                   4000 non-null   object        \n",
      " 10  default                              3698 non-null   object        \n",
      " 11  owns_car                             4000 non-null   object        \n",
      " 12  tenure                               3913 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(2), object(9)\n",
      "memory usage: 406.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display columns of dataset CustomerDemographic\n",
    "print(CustomerDemographic.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3999 entries, 0 to 3998\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   customer_id         3999 non-null   int64 \n",
      " 1   address             3999 non-null   object\n",
      " 2   postcode            3999 non-null   int64 \n",
      " 3   state               3999 non-null   object\n",
      " 4   country             3999 non-null   object\n",
      " 5   property_valuation  3999 non-null   int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 187.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display columns of dataset CustomerAddress\n",
    "print(CustomerAddress.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 13)\n"
     ]
    }
   ],
   "source": [
    "# checking the shape of your data\n",
    "print(CustomerDemographic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3999, 6)\n"
     ]
    }
   ],
   "source": [
    "# checking the shape of your data\n",
    "print(CustomerAddress.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlights of Consistency and Validity in NewCustomerList, Customer Demographic and Customer Address\n",
    "NewCustomerList dataset has 1000 records with 23 columns, yet Customer Demographics have 4000 records with 13 columns and remaining in Customer Address with 6 columns using **customer_id** has key.\n",
    "- Structure format of NewCustomerList must be consistent with Customer Demographic and Customer Address.\n",
    "- There is no **customer_id** in NewCustomerList.\n",
    "- Number of columns are inconsistent because in NewCustomerList there are **4 columns which are Unnamed** and they contain some values as well, however are not labeled so cannot be identified.\n",
    "- There is one column in *NewCustomerList* which is **Value**, it is captured in a column of **float64** datatype but this was not captured before and is not present in *CustomerDemographic* or *CustomerAddress*.\n",
    "- There is one column named **default** in *CustomerDemographic*, it is captured in a column of **object** datatype, some values are observed to be date values but this was not captured after and is not present in *NewCustomerList*. \n",
    "- From remaining columns 5 columns are of datatype **int64** which are past_3_years_bike_related_purchases, tenure, postcode, property_valuation, and Rank.                                . \n",
    "- DOB is the date column **datetime64** in format **YYYY-MM-DD**. The date format used to capture transaction date in Transactions is **MM/DD/YYYY**. It would be better if it is kept consistent.\n",
    "- Rest of the columns are in **object** data type values but, deceased_indicator must have contain **boolean** like True and False.\n",
    "- Data Captured in Gender column in the dataset CustomerDemographic is not consistent. It should be \"Male\", \"Female\" and \"U\" as per the NewCustomerList."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Completeness of Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Total Values  Null_values  \\\n",
      "job_industry_category                         835          165   \n",
      "job_title                                     894          106   \n",
      "last_name                                     971           29   \n",
      "DOB                                           983           17   \n",
      "first_name                                   1000            0   \n",
      "Unnamed: 20                                  1000            0   \n",
      "Unnamed: 19                                  1000            0   \n",
      "Unnamed: 18                                  1000            0   \n",
      "Unnamed: 17                                  1000            0   \n",
      "Unnamed: 16                                  1000            0   \n",
      "property_valuation                           1000            0   \n",
      "country                                      1000            0   \n",
      "state                                        1000            0   \n",
      "address                                      1000            0   \n",
      "Rank                                         1000            0   \n",
      "tenure                                       1000            0   \n",
      "owns_car                                     1000            0   \n",
      "deceased_indicator                           1000            0   \n",
      "wealth_segment                               1000            0   \n",
      "past_3_years_bike_related_purchases          1000            0   \n",
      "gender                                       1000            0   \n",
      "postcode                                     1000            0   \n",
      "Value                                        1000            0   \n",
      "\n",
      "                                     Percentage of Missing Values  \n",
      "job_industry_category                                   19.760479  \n",
      "job_title                                               11.856823  \n",
      "last_name                                                2.986612  \n",
      "DOB                                                      1.729400  \n",
      "first_name                                               0.000000  \n",
      "Unnamed: 20                                              0.000000  \n",
      "Unnamed: 19                                              0.000000  \n",
      "Unnamed: 18                                              0.000000  \n",
      "Unnamed: 17                                              0.000000  \n",
      "Unnamed: 16                                              0.000000  \n",
      "property_valuation                                       0.000000  \n",
      "country                                                  0.000000  \n",
      "state                                                    0.000000  \n",
      "address                                                  0.000000  \n",
      "Rank                                                     0.000000  \n",
      "tenure                                                   0.000000  \n",
      "owns_car                                                 0.000000  \n",
      "deceased_indicator                                       0.000000  \n",
      "wealth_segment                                           0.000000  \n",
      "past_3_years_bike_related_purchases                      0.000000  \n",
      "gender                                                   0.000000  \n",
      "postcode                                                 0.000000  \n",
      "Value                                                    0.000000  \n"
     ]
    }
   ],
   "source": [
    "# looking for the null values\n",
    "total_null_values = NewCustomerList.isnull().sum()\n",
    "\n",
    "# calculating total values\n",
    "total_values = NewCustomerList.count().sort_values(ascending=True) \n",
    "\n",
    "# calculating the percentage of null values\n",
    "null_values_percentage = total_null_values/total_values *100\n",
    "\n",
    "# converting to dataframe of missing values\n",
    "missing_values_NewCustomerList = pd.concat({'Total Values' : total_values, 'Null_values': total_null_values, 'Percentage of Missing Values': null_values_percentage}, axis=1)\n",
    "\n",
    "# display missing values\n",
    "print(missing_values_NewCustomerList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Total Values  Null_values  \\\n",
      "job_industry_category                        3344          656   \n",
      "job_title                                    3494          506   \n",
      "default                                      3698          302   \n",
      "last_name                                    3875          125   \n",
      "DOB                                          3913           87   \n",
      "tenure                                       3913           87   \n",
      "customer_id                                  4000            0   \n",
      "first_name                                   4000            0   \n",
      "gender                                       4000            0   \n",
      "past_3_years_bike_related_purchases          4000            0   \n",
      "wealth_segment                               4000            0   \n",
      "deceased_indicator                           4000            0   \n",
      "owns_car                                     4000            0   \n",
      "\n",
      "                                     Percentage of Missing Values  \n",
      "job_industry_category                                   19.617225  \n",
      "job_title                                               14.481969  \n",
      "default                                                  8.166577  \n",
      "last_name                                                3.225806  \n",
      "DOB                                                      2.223358  \n",
      "tenure                                                   2.223358  \n",
      "customer_id                                              0.000000  \n",
      "first_name                                               0.000000  \n",
      "gender                                                   0.000000  \n",
      "past_3_years_bike_related_purchases                      0.000000  \n",
      "wealth_segment                                           0.000000  \n",
      "deceased_indicator                                       0.000000  \n",
      "owns_car                                                 0.000000  \n"
     ]
    }
   ],
   "source": [
    "# looking for the null values\n",
    "total_null_values = CustomerDemographic.isnull().sum()\n",
    "\n",
    "# calculating total values\n",
    "total_values = CustomerDemographic.count().sort_values(ascending=True) \n",
    "\n",
    "# calculating the percentage of null values\n",
    "null_values_percentage = total_null_values/total_values *100\n",
    "\n",
    "# converting to dataframe of missing values\n",
    "missing_values_CustomerDemographic = pd.concat({'Total Values' : total_values, 'Null_values': total_null_values, 'Percentage of Missing Values': null_values_percentage}, axis=1)\n",
    "\n",
    "# display missing values\n",
    "print(missing_values_CustomerDemographic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlights of Completeness in NewCustomerList, Customer Demographic and Customer Address\n",
    "- In NewCustomerList 19.76% of job_industry_category values are missing almost similar to CustomerDemographic which is 19.61%.\n",
    "- 11.85% of job_title values are missing in NewCustomerList a little less as compared to CustomerDemographic that has 14.48% of missing values.\n",
    "- 3.22% of last_name values were missing in CustomerDemographic yet 2.98% of last_name values are missing in NewCustomerList.\n",
    "- CustomerDemographic has 2.22% of missing DOB values which is slighlty decreased to 1.72% NewCustomerList.\n",
    "- There is a 2.22% of missing tenure values in CustomerDemographic but there is no missing values of tenure in NewCustomerList.\n",
    "- There is 1 missing record of address of **customer_id = 3** in CustomerAddress, as per identified by the shape of the datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Accuracy of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1953-10-12\n",
       "1      1980-12-16\n",
       "2      1954-01-20\n",
       "3      1961-10-03\n",
       "4      1977-05-13\n",
       "          ...    \n",
       "3995   1975-08-09\n",
       "3996   2001-07-13\n",
       "3997          NaT\n",
       "3998   1973-10-24\n",
       "3999   1991-11-05\n",
       "Name: DOB, Length: 4000, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CustomerDemographic['DOB']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlights of Accuracy in NewCustomerList, Customer Demographic and Customer Address\n",
    "One date value is wrong. 1843 year is not possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Uniqueness of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of duplicated records in NewCustomerList dataset is 0\n"
     ]
    }
   ],
   "source": [
    "# looking for duplicated values\n",
    "duplicated_values = NewCustomerList.duplicated()\n",
    "\n",
    "# number of duplicated values in dataset\n",
    "print(\"The number of duplicated records in NewCustomerList dataset is {}\".format(duplicated_values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of duplicated records in CustomerDemographic dataset is 0\n"
     ]
    }
   ],
   "source": [
    "# looking for duplicated values\n",
    "duplicated_values = CustomerDemographic.duplicated()\n",
    "\n",
    "# number of duplicated values in dataset\n",
    "print(\"The number of duplicated records in CustomerDemographic dataset is {}\".format(duplicated_values.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of duplicated records in CustomerAddress dataset is 0\n"
     ]
    }
   ],
   "source": [
    "# looking for duplicated values\n",
    "duplicated_values = CustomerAddress.duplicated()\n",
    "\n",
    "# number of duplicated values in dataset\n",
    "print(\"The number of duplicated records in CustomerAddress dataset is {}\".format(duplicated_values.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlights of Uniqueness\n",
    "All records are unique."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
